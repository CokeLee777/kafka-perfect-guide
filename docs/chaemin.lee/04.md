# Kafka Consumer 개요

- 브로커의 **Topic 메시지를 읽는 역할**을 수행한다.
- 모든 Consumer들은 고유한 group.id를 가지는 **Consumer Group에 소속되어야 한다.**
- 개별 **Consumer Group 내에서 여러 개의 Consumer들은 토픽 파티션별로 분배**된다.

### Consumer의 subscribe, poll, commit 로직

- Consumer는 `subscribe()`를 호출하여 **읽어들이려는 토픽을 등록**한다.
- Consumer는 `poll()` 메서드를 이용하여 **주기적으로 브로커의 토픽 파티션에서 메시지를 가져온다.**
- 메시지를 성공적으로 가져왔으면 commit을 통해서 `__consumer_offset`에 다음에 읽을 offset 위치를 기재한다.

### KafkaConsumer의 주요 구성요소와 poll() 메서드

```java
ConsumerRecords<K, V> consumerRecords = KafkaConsumer.poll(Duration.ofMillis(1000));
```
- 브로커나 Consumer 내부 Queue에 데이터가 있다면 바로 데이터를 반환한다.
- 그렇지 않을 경우에는 1000ms동안 데이터 Fetch를 브로커에 계속 수행하고 결과를 반환한다.

### poll() 메서드의 동작

- KafkaConsumer.poll(1000) 으로 수행 시
	- Linked Queue에 **데이터가 있을 경우 Fetcher는 데이터를 가져오고 반환하여 poll() 수행을 완료**시킨다.
	- ConsumerNetworkClient는 **비동기로 계속 브로커의 메시지를 가져와서 Linked Queue에 저장**한다.
	- Linked Queue에 데이터가 없을 경우 1000ms까지 Broker에 메시지를 요청하여 poll 수행을 완료시킨다.
- 즉, 요약하자면 Queue에 데이터가 있다면 즉시 데이터를 가져오고, Queue에 데이터가 없다면 1초동안 Queue에 데이터가 들어오나 확인하면서 1초안에 데이터가 들어오면 그 즉시 가져온다는 것이다.
- 자세하게는 Fetcher를 통해서 Queue에서 데이터를 가져오고, 데이터가 없다면 ConsumerNetworkClient가 Broker로부터 비동기로 데이터를 가져와서 Queue에 집어넣는 역할을 수행한다.

### Consumer Fetcher 프로세스 개요

- Fetcher는 Linked Queue 데이터를 가져오되, Linked Queue에 데이터가 없을 경우 ConsumerNetworkClient에서 데이터를 브로커로부터 가져올 것을 요청

### Consumer Fetcher 관련 주요 파라미터 이해

- fetch.min.bytes
	- Fetcher가 **record들을 읽어들이는 최소 bytes**를 의미한다.
	- 브로커는 **지정된 fetch.min.bytes 이상의 새로운 메시지가 쌓일 때까지 전송을 하지 않는다.**
	- Default 값은 1이다.
- fetch.max.wait.ms
	- 브로커에 **fetch.min.bytes 이상의 메시지가 쌓일 때까지 최대 대기시간**을 의미한다.
	- fetch.min.bytes 만큼 쌓이지 않는대도 이 대기시간이 다 되면 전송을 하게된다.
	- Default 값은 500ms이다.
- fetch.max.bytes
	- Fetcher가 **한번에 가져올 수 있는 최대 데이터 bytes**를 의미한다.
	- Default 값은 50MB이다.
- max.partition.fetch.bytes
	- Fetcher가 **파티션별로 한 번에 최대로 가져올 수 있는 bytes**를 의미한다.
	- 예를들어 파티션이 10개가 있고, 이 값이 1MB라면 최대 모든 파티션을 합쳐서 10MB를 가져올 수 있다.
	- 하지만 만약 파티션이 100개가 있다면 100MB를 가져올 수 있다고 생각할 수 있지만, fetch.max.bytes에서 걸려서 불가능해진다.
- max.poll.records
	- Fetcher가 Linked Queue에서 **한 번에 가져올 수 있는 레코드 수**이다.
	- Default 값은 500이다.

> [!NOTE]
> KafkaConsumer.poll(1000)으로 수행 할 때
> - fetch.min.bytes = 16384
> - fetch.max.wait.ms = 500
> - fetch.max.bytes = 52428800
> - max.partition.fetch.bytes = 1024168
> - max.poll.records = 500

- 가져올 **데이터가 1건도 없으면 poll() 인자 시간만큼 대기 후 반환**한다.
- 가져와야할 과거 데이터가 많을 경우 max.partition.fetch.bytes로 배치 크기를 설정한다. 그렇지 않을 경우fetch.min.bytes로 배치 크기를 설정한다.
- 가장 최신의 offset 데이터를 가져오고 있다면 fetch.min.bytes 만큼 가져오고 반환하고, fetch.min.bytes만큼 쌓이지 않는다면 fetch.max.wait.ms 만큼 기다린 후 반환한다.
- 오랜 과거 offset 데이터를 가져온다면 최대 max.partition.fetch.bytes 만큼 파티션에서 읽은 뒤 반환한다.
- max.partition.fetch.bytes에 도달하지 못해도 가장 최신의 offset에 도달하면 반환한다.
- **토픽에 파티션이 많아도** 가져오는 데이터량은 **fetch.max.bytes로 제한**한다.
- Fetcher가 Linked Queue에서 가져오는 레코드의 개수는 max.poll.records로 제한한다.

### Consumer의 subscribe, poll, commit 로직

- Consumer는 subscribe()를 호출하여 **읽어들이려는 토픽을 등록**한다.
- Consumer는 poll() 메서드를 이용하여 **주기적으로 브로커의 토픽 파티션에서 메시지를 가져온다.**
- 메시지를 성공적으로 가져왔으면 commit을 통해서 `__consumer_offset` 에 **다음에 읽을 offset 위치를 기재**한다.

### Consumer의 auto.offset.reset

- Consumer가 Topic에 처음 접속하여 Message를 가져올 때 **가장 오래된 처음 offset부터(earliest) 가져올 것인지, 가장 최근인 마지막 offset 이후부터 가져올 것인지를 설정하는 파라미터**이다.
- auto.offset.reset = earliest
	- 처음 offset부터 읽는다.
- auto.offset.reset = latest
	- 마지막 offset부터 읽는다.
- 동일 Consumer Group으로 Consumer가 새롭게 접속할 시 `__consumer_offsets` 에 있는 offset 정보를 기반으로 메시지를 가져오기 때문에 earliest로 설정하여도 0번 오프셋부터 읽어들이지 않는다.
	- 즉, Consumer Group에 있는 Consumer 1이 offset 10번까지 이미 읽고 `__consumer_offsets` 가 11이라면 새롭게 Consumer Group에 Consumer 2가 들어가도 offset 0번부터 읽어들이지 않는다는 뜻이다.
- Consumer Group의 Consumer가 **모두 종료되어도 Consumer Group이 읽어들인 offset 정보는 7일동안 `__consumer_offsets` 에 저장**되어 있다.(offsets.retention.minutes)
- 해당 Topic이 **삭제**되고 **재생성**될 경우에는 해당 topic에 대한 Consumer Group의 offset 정보는 **0으로 `__consumer_offsets` 으로 기록**된다.

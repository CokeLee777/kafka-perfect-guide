# 멀티 노드 카프카 클러스터

- **분산 시스템**으로서 카프카의 **성능과 가용성을 함께 향상**시킬 수 있도록 구성
- **스케일 아웃 기반**으로 노드 증설을 통해서 **카프카의 메시지 전송과 읽기 성능을 선형적으로 증가**시킬 수 있다.
- 데이터 복제(Replication)을 통해서 분산 시스템 기반에서 카프카의 최적 가용성을 보장한다.

### 분산 시스템 구성을 위한 중요 요소

- 분산 시스템 도입을 위해서는 **성능, 안정성, 가용성 측면에서 상세한 기능 검토가 요구**된다.
- 분산 시스템은 **대량 데이터를 여러 노드간 분산처리를 통해 빠르게 처리할 수 있는 큰 성능적 이점**을 가지지만, **안정성과 가용성 측면에서 상대적인 단점**을 가진다.

#### 단일 노드 구성(Scale Up)

처리하려는 데이터가 기하 급수적으로 늘어난다면?

- H/W를 CPU Core, Memory 용량, 디스크 용량, 네트웍 Bandwidth를 **Scale Up 방식으로 증설하기에는 한계**가 있다.(비용적인 측면이나, H/W 아키텍처 등)
- 단일 노드에 대해서만 가용성 구성을 강화하면 되므로 **매우 안정적인 시스템 구성이 가능**하다.
- 소프트웨어에서 **다양한 성능향상 기법을 도입하기 매우 쉽다.**

#### 다수의 노드로 분산 구성

- 개별 H/W 노드를 Scale Out 방식으로 증설하여 대용량 데이터 성능 처리를 선형적으로 향상
- 다수의 H/W가 1/N의 데이터를 처리하므로 이중 **한 개의 노드에서만 장애가 발생해도 올바른 데이터 처리가 되지 않는다.**
- **다수의 H/W로 구성하였으므로 빈번한 장애 가능성, 관리의 부담**
- 소프트웨어 자체에서 성능/가용성 처리 제약

### 멀티 노드 카프카 클러스터

- 분산 시스템으로서 카프카의 **성능과 가용성을 함께 향상** 시킬 수 있도록 구성
- 스케일 아웃 기반으로 **노드 증설을 통해 카프카의 메시지 전송과 읽기 성능을 (거의) 선형적으로 증가**시킬 수 있음
- 데이터 복제(Replication)을 통해 분산 시스템 기반에서 카프카의 최적 가용성을 보장한다.

### 카프카 Replication

- 카프카는 개별 노드의 장애를 대비하여 높은 가용성을 제공한다.
- 카프카 가용성의 핵심은 리플리케이션(Replication, 복제)
- Replication은 토픽 생성 시 **replication factor** 설정값을 통해 구성한다.
- Replication factor가 3이면 **원본 파티션과 복제 파티션을 포함하여 모두 3개의 파티션을 가짐을 의미**한다.
	- 각 브로커가 모두 3개의 파티션을 보유하고 있음을 의미한다.
- Replication factor의 개수는 **브로커의 개수보다 클 수 없다.**
	- 브로커의 개수보다 Replication Factor가 크다면 토픽 생성 시 오류가 발생한다.
- Replication의 동작은 토픽내의 개별 파티션들을 대상으로 적용한다.
- Replication factor의 대상인 파티션들은 1개의 Leader와 N개의 Follwer로 구성된다.

#### 카프카 Replication의 Leader와 Follwer

- Producer와 Consumer는 **Leader 파티션을 통해서 쓰기와 읽기를 수행**한다.
- 파티션의 Replication은 **Leader에서 Follwer으로만 이뤄진다.**
	- 실제로 Leader가 Follwer에게 주는것이 아닌 **Follwer가 Leader로부터 메시지를 가져와서 복제하는 메커니즘으로 구현**되어있다.
- 파티션 리더를 관리하는 브로커는 Producer/Consumer의 읽기/쓰기를 관리함과 동시에 파티션 팔로우를 관리하는 브로커의 Replication도 관리한다.

![](./images/replication.png)

##### 단일 파티션의 Replication(복제)

- 파티션의 Replication은 **Leader에서 Follwer으로만 이루어진다.**
- 파티션 리더를 관리하는 브로커는 Producer/Consumer의 읽기/쓰기를 관리함과 동시에 파티션 팔로우를 관리하는 브로커의 Replication도 관리한다.

![](./images/single_replication.png)

- 위 그림처럼 `acks=all` 이라고 가정하자.
- Producer가 메시지 A를 전달하면 무조건 Partition Leader가 있는 곳으로 쓰여진다. 따라서 Broker #1 에 메시지 A가 쓰여진다.
- Follower Partition이 존재하는 Broker #1, #2 는 이를 인지하고 Partition Leader에 쓰여진 메시지 A를 가복제해서 가져와 자신의 Follower Partition에 메시지 복제본을 쓰게된다.
- Leader Partition과 Follower Partition 들에 메시지가 모두 쓰여진 것을 확인하고 Partition Leader를 보유한 Broker는 Producer에게 ACK 신호를 보내게된다.

##### 멀티 파티션의 Replication(복제)

- 파티션의 Replication은 Leader에서 Follower으로만 이루어진다. (Follower에서 Leader 파티션을 읽어간다.)
- 파티션 리더를 관리하는 브로커는 Producer/Consumer의 읽기/쓰기를 관리함과 동시에 파티션 팔로우를 관리하는 브로커의 Replication도 관리한다.

![](./images/multi_replication.png)

- 위 그림과 같이 해당 토픽은 파티션이 3개이고 replication-factor가 3이라고 가정하자.
- 메시지 1의 목적지는 Partition #1 이므로 해당 파티션이 Leader인 Broker #1 에게 메시지가 쓰여진다.
	- 그런 다음 Follower Partition이 존재하는 Broker #2, #3 의 Follower Partition #1 으로 복제가 되어진다.
- 메시지 2의 목적지는 Partition #2 이므로 해당 파티션이 Leader인 Broker #2 에게 메시지가 쓰여진다.
	- 그런 다음 Follower Partition이 존재하는 Broker #1, #3 의 Follower Partition #2 으로 복제가 되어진다.
- 메시지 3의 목적지는 Partition #3 이므로 해당 파티션이 Leader인 Broker #3 에게 메시지가 쓰여진다.
	- 그런 다음 Follower Partition이 존재하는 Broker #1, #2 의 Follower Partition #3 으로 복제가 되어진다.

# Java 기반 Producer 구현 실습 및 Producer 내부 메커니즘 이해 - 02

![image](https://github.com/CokeLee777/kafka-perfect-guide/assets/66711073/10e14cf0-38d8-4893-98bb-76586e9519a7)

> MULTI BROKER 환경에서 leader partition을 복제한 follewer partition이 타 broker에 있다. 
>
> Producer는 해당 topic의 Partiotion의 leader broker에게만 메시지를 보낸다.
>
> 그리고 브로커2, 브로커3 partition에 메시지가 복제되는 것이다.

## 1. acks 값 설정에 따른 Producer의 전송 방식 차이

acks (인지했냐) 에 따라 send 방식에 차이가 있다.

### acks 
- producer 가 메시지를 보낸 뒤 broker 에게 ack 확인을 어떻게 받을지 결정하는 옵션
- dafault 가 all 임.

### 1. acks = 0 일 때
-> broker가 ack 메시지를 보내지 않음. producer 는 broker의 ack를 전혀 안 기다림. (file and forger)

- producer는 offset을 받을 수 없기에, 메시지를 정상적으로 받았는지에 대해 알 수 없다.
- producer는 실제 브로커에 저장됐는지 확인 없이, 보장 없이, 다음 메시지를 바로 전송한다.
- 메시지가 제대로 전송되었는지 브로커로부터 확인을 받지 않기 때문에, 메시지가 브로커에 기록되지 않는 누락에도, 재전송할 수 없는 구조

- 가장 빠르게 전송 가능.
- 메시지 손실의 우려가 가장 큼.
- IOT 센서 데이터 등 데이터 손실에 민감하지 않은 데이터 전송에 활용.

<br>

> *브로커1일 땐, acks 1과 all이 같으나, 멀티브로커 상황에선 다르다.*

### 2. acks = 1 일 때
->leader partition에만 잘 갔는지 확인하고 ack를 보냄. 모든 복제본이 정상적으로 만들어졌는지 확인을 안함.

- producer는 leader partition 가 메시지 a를 정상적으로 받았는지에 대한 ack 메시지를 받은 후 다음 메시지인 메시지 b를 전송. 만약 오류 메시지를 브로커로부터 받으면 메시지 a를 재전송
- 메시지 a가 **모든 replicator에 완벽하게 복사되었는지의 여부는 확인하지 않고 메시지 b를 전송**
- 만약, leader가 메시지를 복제 중에 다운될 경우, 다음 leader가 될 브로커에는 메시지가 없을 수 있기 때문에 메시지를 소실할 우려가 있음.

### 3. acks = all (-1) 일 때
-> 모든 복제본을 확인 하고, acks를 producer 에게 줌.

- Producer는 Leader partition이 메시지a를 정상적으로 받은 뒤, min.insync.replicas 개수 만큼의 replicator에 복제를 수행한 뒤,
  
  모든 follower 의 ack 를 받은 후, 다음 메시지 b 를 전송.
- 메시지 a가 모든 replicator에 완벽하게 복사되었는지의 여부까지 확인 후에 메시지 b를 전송
- 메시지 손실이 되지 않도록 모든 장애 상황을 감안한 전송 모드
- ack 를 오래 기다려야 하므로 상대적으로 전송 속도가 느림.

> *replication 이 성공적으로 되었는지는 leader broker가 어떻게 아나?*
  
<br>

**min.insync.replicas 파라미터**
  - 몇 개 복제본을 확인하고 acks를 줄 건지 설정하는 파라미터
  - replication-factor = 3 , min.insync.replicas = 2 일 때,

    1개가 죽어도 정상. 2개 죽으면, error:NOT_ENOUGH_REPLICAS 를 보냄.

<br>

### sync / async 별, acks 
- Sync
  - send() 호출 → 결과가 돌아올 때까지(ack/error) 블로킹.
  - 즉, ack이 오거나 에러가 나야 다음 코드 실행.
- Async
  - send() 호출 → 바로 return (Future 객체를 돌려줌).
  - ack/error는 콜백(callback) 으로 받음.

| 모드        | acks=0                                            | acks=1                         | acks=all                         |
| --------- | ------------------------------------------------- | ------------------------------ | -------------------------------- |
| **Sync**  | ack 기다려도 broker가 안 주니까 → 동기적 호출 이지만, Future 가 즉시 완료 상태로 처리 -> **즉시 return, offset=-1(알수없음 의미)** -> 의미없는 offset | 리더 응답 올 때까지 기다림 → offset 확보 가능 | 리더+팔로워 복제까지 기다림 → offset 확보 가능   |
| **Async** | 브로커 응답 안줌. -> RecordMetadata 콜백이 실행됨. (offset=-1(알수없음 의미), partition, topic 정상값) -> 의미없는 offset    | 콜백으로 리더 응답 받음 → offset 확보 가능   | 콜백으로 리더+팔로워 응답 받음 → offset 확보 가능 |

**정리**
1. acks 는 producer - broker 간의 응답 약속이고, sync / async 는 Producer code 에서 응답을 어떻게 기다리냐 이다
2. ack = 1, -1 일 땐 acks 응답을 producer 에게 주기 때문에, retry를 할 수 있으나,
  - 0 일 땐 producer 는 acks 를 받지 못하기 때문에 데이터 누락 장애를 알 수 없고, 그러므로 retry 를 할 수 없다.

<br>

3. sync + acks=0 → 동기로 호출했지만,
  - broker가 응답을 안 하니, **Future 가 즉시 완료 상태로 처리** 되는 것이다.
  - 이때, get()을 호출에서 RecordMetadata 객체를 반환하는데,
    - offset: -1 (브로커가 저장해야 할 때만 알 수 있는 값인데, ack=0 이라 broker 응답을 안 해서 모름)
    - partition: 정상 값 (Producer 내부 partitioner가 계산해서 이미 알고 있음 → key 기반, round-robin 등)
    - topic: 정상 값 (Producer가 알고 있음)
  - 그래서 .get()에서도 예외는 발생하지 않고, 단지 offset=-1인 metadata만 반환

<br>

4. callback 기반의 async에서는 callback 일 경우, ack = 1, -1 일 때, 발생할 수 있는 retry에 따라서  producer의 원래 메시지 전송순서와 broker에 기록되는 메시지 전송 순서가 변경 될 수 있다는 것을 알아야 한다.


## 2. Producer의 메시지 배치 전송의 이해

**producer main thread는 producer record는 하나씩 보내나, 그러나, 실제 broker에 보낼 때는 배치 단위로 보낸다.** 

```RecordMetadata recordMetadata = kafkaProducer.send(producerRecord).get()```

- main thread에서 호출하는 send() 메소드는 실제로 record accumulator 에 배치 형태로 저장하고 반환하는 역할만을 한다.
- 실제 전송을 시키는 것은 sender thread가 배치 단위로 읽어 broker로 보냄.
- 그래서 사실, 위 코드에서 send() 메소드는 main thread가 accumulator 에 메시지를 저장했으면,      

  recordMetadata를 반환한다. 그래서 본질적으로 send() 메소드까진 비동기 였다.

  그래서 send thread가 메시지를 들고 올 때 까지 묶어두는 게, get() 이였다.


:star: 
Serialize -> Partitioning -> Compresstion(선택) -> **RecordAccumulator 저장 -> Sender에서 별도의 Thread로 전송**

- Kafka Producer 객체의 send() 메소드는 호출 시마다 하나의 ProducerRecord 를 입력하지만,

  바로 전송되지 않고 내부 메모리 RecordAccumulator 에서 단일 메시지를 토픽 파티션 (갈 목적지)에 
  
  따라 Record Batch 단위로 묶인 뒤, 전송됨.
  - 어느 patition 으로 갈지, RecordAccumulator에 저장될 때, 이미 결정해서 partition 별로 저장됨.
    
    sender thread는 이걸 그대로 배치 단위로 읽어와 브로커로 보내는 것.


- buffer.memory 파라미터
  - RecordAccumulator는 메시지들을 해당 파라미터 사이즈 만큼 보관될 수 있으며,
  
    여러 개의 Batch 들로 ? 한꺼번에 전송될 수 있음.


### Record Accumulator
: Partitioner에 의해서 메시지 배치가 전송이 될 토픽과 patition에 따라 저장되는 kafka 메모리 영역

![image](https://github.com/CokeLee777/kafka-perfect-guide/assets/66711073/7b9f27d3-abe1-4b72-bca0-d0ff38bb1e56)

- sender thread가 여기서 배치 단위로 읽어, 즉, 누적된 메시지 배치를 브로커로 보낸다.
- partition 목적지 별로 batch 쌓인다.
- key, value 형태로 되어 있음.

- 그래서 사실, main thread가 accumulator에 계속적으로 메시지 쌓아야 하는데, get() 동기 시, 브로커로 부터 성공을 확인 못하면, main thread가 다음 메시지를 보내지 않으니, 성능이 떨어질 수 밖에

![image](https://github.com/CokeLee777/kafka-perfect-guide/assets/66711073/313edcc7-1a4d-46a5-9223-0cc8c27eb267)

![image](https://github.com/CokeLee777/kafka-perfect-guide/assets/66711073/06a06156-2b0c-4799-bac2-858a3412b0d1)

- sender thread가 기본적으로 전송 할 준비가 되었다면, 배치가 다 안 차도 그냥 브로커로 갈 수 있다.

- ```linger.ms``` 파라미터
  - sender thread로 메시지를 보내기 전 배치로 메시지를 만들어서 보내기 위한 최대 대기 시간

    배치가 쫌 찰 때까지 기다릴 시간을 가지게 하는 것.

- ```buffer.memory``` 파라미터
  - RecordAccumulator 의 전체 메모리 사이즈

- ```batch.size```
  - 단일 배치의 사이즈

=> batch.size 과 linger.ms 를 조절하여, 보낼 배치의 크기를 조절한다.
- linger.ms 를 0 보다 크게 설정하여 sender가 하나의 record batch를 가져갈 때 일정 시간 대기하여,

  record batch에 메시지를 보다 많이 채울 수 있도록 적용

<br>

- 1개의 batch를 가져갈 수도 있고, 여러 개의 batch 를 가져 갈 수 도 있다.

**:question: 여러 개의 batch 를 가져가는 메커니즘**

```max.in.flight.requests.per.connection = 2```

같은 partition으로 가는 배치가 최대 2개 까지 같이 브로커로 갈 수 있다.

### linger.ms
- linger.ms 를 반드시 0 보다 크게 설정할 필요는 없음.
- producer와 broker 간의 전송이 매우 빠르고 producer에서 메시지를 적절한 record accmulaor에  누적된다면 0 이여도 무방
- 전반적인 producer 와 broker 간의 전송이 느리다면, linger.ms 를 높여서 메시지가 배치로 적용될 수 있는 확률을 높이는 시도를 해볼 만 하다.
- linger.ms 를 보통 20ms 이하로 설정 권장한다.

## 3. 동기, 비동기에서 배치 전송 차이
- 기본적으로 kafkaProducer 객체의 send () 는 비동기이며, batch 기반으로 메시지를 전송한다.
- callback 기반의 async과 위의 차이는, 비동기적으로 메시지를 보내면서, **RecordMetadata를 client가 받을 수 있다는 것이 차이.**
- Callback 기반의 async 는 여러 개의 메시지가 batch로 만들어짐.
- 근데, 이때 RecordMeataData recordMetadata = KafkaProducer.send().get() 와 같은 방식으로 개별 메시지 별로 응답을 받을 때까지 block 이 되는 방식으로는 **메시지 배치 처리가 불가능**하다. 전송은 배치 레벨이지만 배치에 메시지가 단 한 개 들어가게 된다.

## 4. 재전송 내부 메커니즘

👍 헷갈리지 말아야 할 것 async든 sync 든 acks, retry 는 동일하게 적용.

분산 시스템에서 네트워크 장애는 흔하게 발생하는데, 이러한 재전송 메커니즘 등을 이루는 카프카는 

굉장히 안정적인 시스템이라고 할 수 있다.

![image](https://github.com/CokeLee777/kafka-perfect-guide/assets/66711073/283776cd-87d7-4d90-ac12-a1dfdf40fc06)

### 전송 및 재전송 시간 파라미터

```max.block.ms```

send() 호출 시, record accumulator 에 입력하지 못하고 block되는 최대 시간. 초괴 시, timeout exception.

``linger.ms``

sender thread가 record accumulator에서 배치별로 가져가기 위한 최대 대기 시간

```request.timeout.ms```

전송에 걸리는 최대 시간. 전송 재시도 대기 시간 제외.

초과 시, retry 또는 timeout exception 발생

```retry.backoff.ms```

sender thread가 재시도 하기 전 조금 기다리는 시간. 전송 재시도를 위한 대기 시간.

```delivery.tineout.ms```
producer 메시지(배치) 전송에 허용된 최대 시간. 초과 시, timeout exception 발생
언제까지 재전송을 시도 하냐. 파라미터 ms 시간 동안 재전송을 시도한다.

**delivery.timeout.ms >= linger.ms + request.timeout.ms 이여야 한다.**

안 그러면 exception


``retries``

몇 번 재전송할 거냐. 재전송 횟수를 설정

굉장히 큰 값을 해둠. 그 횟수 만큼 재전송 시도하다가, 

어차피 delivery.tineout.ms 파라미터에 의해 끝나서 그만큼 안 함.

-> **보통 retires 는 무한대값으로 설정하고**

**delivery.timeout.ms(기본 120000, 즉 2분) 를 조정하는 것을 권장.**


*retry 메커니즘을 콘솔로 출력, 확인할 순 없다.*

## 5. max.inflight.requests.per.connection 파라미터와 배치 메시지의 전송순서 이해

**broker 서버의 응답없이 acks 없이** producer의 sender thread가 보낼 수 있는 배치의 개수.

해당 파라미터는 send thread와 broker 간의 전송과 관련된 파라미터이다.

비동기 전송 일 때도 계속적으로 send thread가 보내는 것이 아니라, 해당 파라미터의 갯수만큼 까지 브로커에 보낼 수 있는 것이다.


- defalut 5
- **사실, 브로커에도 배치단위로 저장되고, acks 보낼 때도 배치 단위로 acks 가 날라옴.**

### 재전송 메커니즘
비동기 상황에서

max.inflight.requests.per.connection 만큼 브로커에 보낼 수 있다.

sender thread는 보낸 만큼, acks 를 브로커에서 받기를 기다린다. acks 가 하나라도 와야 

다음 메시지를 보낼 수 있다.

비동기 상황에서도, 해당 메커니즘으로 실질적으로 브로커에 보낼 수 있는 배치 갯수를 조절할 수 있는 것이다.

### 배치 전송 에서 재전송 발생 시, Producr 메시지 전송 순서 != 메시지 저장 순서

B0 가 B1 보다 Producer 에서 생성된 메시지 배치 상황이다.

ax.inflight.requests.per.connection = 2(>1) 에서

B0, B1 2개의 배치 메시지를 전송 시 B1 은 성공적으로 기록되었으나,

B0 의 경우, Write 되지 않고 ack 전송이 되지 않는 failure 상황이 된 경우,

producer는  B0 을 재전송하여 성공적으로 기록되었다면,

Producer의 원래 메시지 순서와는 다르게 broker에 저장 될 수 있음.

- 버전업되면서 이 문제를 해결하기 위한 파라미터 enable.idempotence=true 가 나왔다.

  max.in.flight.requests.per.connection이 1보다 큰 경우 발생할 수 있는 메시지 순서 이슈를 해결하는 파라미터


=> 그러나, 사실, 분산시스템 카프카는 이 문제에 대해 중요하게 생각하지 않고 이보다 성능 속도를 우선시 생각하는 솔루션이다.

  일자를 넣는 방식 등 비즈니스 로직을 통한 해결을 생각해볼 수도 있다.

  만약, 이 문제를 중요하게 여긴다면, 분산 시스템이 아닌 다른 시스템을 고민해야 할 듯.

## 6. 최대 한번 전송, 적어도 한 번 전송, 정확히 한 번 전송
### 1. 최대 한 번 전송 at most once
- 중복을 허용 안 함. 두 번 보내지 않음.
- 브로커가 ack를 보내든 안 보내든, producer 가 acks 를 기다리지 않고 그냥 다음 메시지를 보냄. 어떤 상황이든 딱 한 번만 보내는 것.
- 메시지가 소실 될 수는 있지만 중복 전송을 안 함.

### 2. 적어도 한 번 전송 at least once
- 중복을 허용 함.
- producer는 broker로 부터 ack 를 기다린 후, 메시지를 b를 전송힌다. 이때, 안 오면 retry 를 시도한다.
- retry (acks 1, all) 을 할 경우에, 중복이 될 수 있는 상황이 발생할 수 밖에 없다.
  메시지 a 가 잘 왔는데, acks 를 못 보냈을 경우도 있다. 이럴 때도 재전송이 이러나는데, 이 경우 
  
  메시지는 중복 될 것이다.
- 메시지 소실은 없지만 중복 전송을 할 수 있음.
- 사실 분산 시스템에서 안전성을 위해 retry를 해야 한다.

### 3. 정확히 한 번 전송 exactly once 

**1) Transaction 기반 전송**
  - 보통 **정확히 한 번 전송**을 한다는 것은 **트랜잭션 기반 전송**이다.
  - Transaction 기반 전송을 하려면 Idempotnece 여야 한다.
  - 써야 하는 상황
    - Consumer -> Process -> Producer (ex. 주로 Kafka Streams)에서 주로 사용되는 Transaction 기반 처리 한다. 여러 개의 process 로 이뤄져 있는 경우, 해당 기반을 사용한다.

**2) 중복 없이 전송(멱등성 Idempotence : 여러 번 해도 같은 결과를 불러온다.)**
- **producer 레벨에서 message 중복 제거**를 하는 것을 말한다.
- retry 를 하는데, 중복을 제거 하는 것.

<br>
<br>

**1. 메커니즘**

producer는 브로커로부터 ack 를 받은 다음에 다음 메시지를 전송하되, 

**프로듀서 id와 메시지 squence 를 header 에 저장하여 전송하고, 브로커에 저장된다.**

브로커 측에서는 파티션별로 성공적으로 기록된 pid, 최대 sequence을 찾게 되고,
  
=> 이미 있는 suqeunce 를 가진 message를 보냈을 경우, **브로커에서 메시지가 중복될 경우, 이를 메시지 로그에 기록하지 않고, ack만 전송한다.**

=> 또, sequence + 1 인 메시지가 아닐 경우에는, OutOfOrderSequenceException 을 보내, 메시지 전송 

즉, 순서도 보장 되게 된다.

<br>

**producer id**
- producer 가 기동시마다 새롭게 생성. 재기동하면 바뀜.

**메시지 squence**
- 메시지의 고유 sequence 번호. 0 부터 시작하여 순차적으로 증가. 이를 통해 메시지 자체를 구분할 수 있다. 순차적으로 증가하기에, 메시지 순서도 알 수 있다.

<br>

**2. Idempotence 기반에서 메시지 전송 순서 유지**
B0 이 가장 먼저, B1, B2 순에서 producer 에서 생성된 메시지 배치 상황이다.

Idempotence 기반에서 max.in.flight.requests.per.connection 만큼 여러 개의 배치들이 broker에 전송이 된다.

broker는 메시지 배치를 처리 시, write 된 배치의 마지막 메시지 sequence + 1이 아닌 배치 메시지가 올 경우

OutOfOrderSequenceException 을 생성하여 producer 에 오류로 전달한다.

이를 통해 메시지 배치 간의 순서를 보장할 수 있다.

<br>

**3. Idempotence 를 위한 Producer 설정**
- enable.idempotence = true
- acks = all
- retries 는 0보다 큰 값
- max.in.flight.requests.per.connection 은 1에서 5 사이 값
  - 최대 5인 이유는? 
  - idempotence 를 유지하기 위해서 내부적으로 가지는 캐시 max.in.flight.requests.per.connection 갯수가 5 정도 수용할 수 있다.
  - 해당 파라미터가 1보다 크면 순서가 바뀔 수 있는데,
    - 이때, enable.idempotence = true 하면, 여러 개의 배치가 들어 왔을 때, ordering 이 가능하다. 이를 통해 메시지 전송 순서를 보장할 수 있다.

<br>

- idempotence 적용 후 성능이 약간 감소 (최대 20 %)할 수 있지만 기본적으로 idempotence 적용을 권장.

<br>

**✅ 파라미터 설정 시, 유의 사항**
<br>

  - kafka 3.0 부터는 producer의 기본 설정이 Idempotence 이다.

<br>

1. 디폴트 idempotence 설정 한 경우, ( enable.idempotence = true 명시적 설정을 안 한 경우.)

  기본 설정 중에 enable.edempotence = true 를 제외하고 

  다른 파라미터들을 잘못 설정하면, (예를 들어, acks = 1)

  producer 는 정상적으로 메시지를 보내지만 iempotence 로는 동작하지 않음.


2. 명시적으로 enable.idempotence = true 를 설정한 경우

  다른 파라미터들을 잘못 설정하면 config 오류가 발생하면서 producer 가 기동되지 않음.

## 7. Partitioner : Producer의 메시지 파티셔닝
메시지가 토픽의 어떤 파티션으로 갈 것인지를 결정.

### 1. Default partitioner
- 커스텀 하지 않은 경우
- kafkaProducer는 기본적으로 DefaultPartitioner 클래스를 이용하여 메시지 전송 시 도착할 partition을 지정

1. 메시지의 key 값이 있는 경우, key 값을 hasing 함. 

key 값의 hash 를 통해

토픽 partition 들에 메시지가 갯수가 고르게 균일하게 전송할 수 있도록 한다. 

2. 메시지의 key 값이 없는 경우,

스티키 파티셔닝을 통해 메시지가 분배된다.


### 2. custom partitioner

key 값에 따라 patitioning을 custom 할 수 있다.

- custom partitioning 클래스를 구현하기 위해서는 

  partitioner Interface 를 Implementation 해야 함.

- partition() 메소드에 custom partitioning 로직을 직접 구현.


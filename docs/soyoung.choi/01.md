# 01-1 Topic과 Partition 그리고 카프카 병렬 분산 처리 개요

### 카프카 토픽 개요
- messsage 를 저장하는 핵심
- 여러 개의 **partition** 으로 구성된 일련의 **로그** 파일
  - **partition 은 카프카 메시징 병렬 분산 처리**의 핵심
- 정보를 저장한다는 의미에서 RDBMS의 Partition Table과 유사한 기능이라 할 수 있음.
  - 일련의 로그 파일이라는 것이 차이
- key 와 value 기반의 메시지 구조이며, value로 어떤 타입의 메시지도 가능 (문자열, 숫자값, 객체, json, Avro, Protobuf 등 )
- 로그 파일과 같이 연속적으로 추가되고 발생하는 데이터를 저장하는 구조

<br>

:star: **시간의 흐름에 따라, 메시지가 순차적으로, 물리적인 파일에 write 됨.**
  - 메시지를 보내면 보낼수록 offset 이 증가하면서 순차적으로 계속 write 추가되는 구조 (offset이 낮다는 것은 과거에 보냈다는 의미)
  - update가 그런 것 없이 그냥 append 계속 추가되는 것.!
  - 시간의 흐름. 시계열적인.

img 01. 토픽개요

### 토픽과 파티션
- topic은 1개 이상의 파티션을 가질 수 있음.
- topic의 partition은 **kafka의 병렬 성능과 가용성 기능**의 핵심 요소이며,

  메시지는 병렬 성능과 가용성을 고려한 개별 파티션에 분산 저장됨.
- message data가 partition#0 으로 갈 수도 있고 partition#1로도 갈 수 있는 것.


02-포픽과파티션.png

### 토픽과 파티션, 오프셋
- **개별 파티션은 정렬되고, 변경할 수 없는 (immutable) 일련의 레코드**로 구성된 로그 메시지

  => distibuted partitioned immutable Log

- 개별 레코드는 offset으로 불리는 일련 번호를 할당 받음.
- 개별 파티션은 다른 파티션과 완전히 독립적임.
  - offset은 patition 별로 독립적임. 완전히 분리되어, 각각의 partition에서 증가.
- **개별 파티션 내에서 정렬되고 offset이 할당**됨.

### 토픽과 파티션의 병렬 분산 처리
메시지는 **병렬 성능**과 **가용성**을 고려한 방식으로, 

토픽 내의 개별 파티션들에 분산 저장됨.

03-병렬 분산 처리.png

또한, 토픽의 파티션들은 단일 카프카 브로커 뿐만 아니라 여러 개의 카프카 브로커 들 (여러 노드)에 분산 저장됨.

01-병렬 분산 처리-여러개의 카프카브로커.png

### 가용성의 의미
만약, 한 서버(한 브로커)에 문제가 생겨, 브로커 a가 꺼진다고 했을 때,  

브로커 b의 토픽만 읽을 수 있다면? 그리고 꺼진 브로커의 메시지를 잃는다면? 아주 큰 문제일 것이다.

:star: 그래서 분산 시스템은 필연적으로 가용성이 중요하다.

01-5 카프카클러스터.png

**HOW ?** 

=> **relication-factor = 2**

  복제 영역을 가지게 되며, 다른 broker에 복제본을 둔다. 

  producer 에서 send 하면 partition leader에게만 데이터가 간다.
  
  그리고 그 데이터를 follower 에 복제를 한다.
  
  => **만약, 하나의 broker 가 죽을 때, 복제본이 leader 역할**을 하게 되면서 여기에 메시지가 쌓이는 것이다.
  
  즉, 가용성을 보장할 수 있게 된다.!!

- 이러한 replication 은 스토리지가 많이 들게 되는 단점이 있다.

# 01-2 Topic 명령어

### Topic 생성 및 정보 확인
- ```$CONFLUENT_HOME/bin/kafka-topics command``` 를 이용

1. ```--bootstrap-server```
- Topic을 생성할 kafka broker 서버 주소 : Port

  - --bootstrap-server localhost:9092

2. ```--create```

- --topic : 기술된 topic 명으로 topic 신규 생성

- --partitions: topic의 파티션 개수

  -  기본 설정 디폴트값으로 1 (/$CONFLUENT_HOME/etc/kafka/server.prop* 에서 num.partitions 에서 변경 가능)

- --replication-factor : replication 의 개수

3. ```--list```

- 브로커에 있는 topic 의 리스트

4. ```--describe```

- --topic : 기술된 특정 topic 명으로 상세 정보 표시


---
- 저장 단위는 토픽 단위가 아니라, 파티션 단위
  /data/kafka-logs 에서 파티션 단위 볼 수 있고, 메시지 로그 확인할 수 있음.

# 01-3 Producer 와 Consumer 개요

01-6 Producer와 consumer 개요.png

### 1. Producer
- topic에 메시지를 보내는 역할 (메시지 write)
- 메시지가 serializer 단계를 거치고, 어느 브로커, 어느 파티션으로 갈지 결정을 하여 보내진다.
- 이렇게 보내진 메시지는 broker가 일련의 연속된 시계열성을 기반으로 로그파일을 기록하게 된다.

**어떤 메시지가 어느 파티션에 가는지는 어떻게 정해지나?**
- Producer는 성능/로드밸런싱/가용성/업무 정합성 등을 고려하여 어떤 브로커의 파티션으로 메시지를 모내야 할지 __전략적__으로 결정됨.

**Producer 의 구성**

- Record = Message = Event
- key는 어디에 메시지를 보내야 할지 결정하는 축이 된다.
- Record 에 반드시 들어가야 할 것 : Topic, Value

### 2. Consumer 
- Topic에서 메시지를 읽어 들임
- 여러 개의 Consumer들로 구성될 경우 어떤 브로커의 파티션에서 메시지를 읽어들일지 전략적으로 결정함.
- Subscribe & Poll 하며 데이터를 하나씩 땡겨간다.
  - 이렇게 땡겨가도, 메시지는 partition에 그대로 유지하고 있음. 없어지지 않음. 다른 consumer가 와서 이것을 가져갈 수 있음.
    - 다른 mq 랑 다른 점.


### Kafka Producer의 send() 메소드 호출 프로세스

01-7 Kafka Producer의 send()메소드 호출 프로세스.png

- partitioner 에서 batch에 메시지를 담음.
partition 1번에 갈 배치에 여러 메시지 row을 담게 되고, => **배치레벨로 send**한다.
- batch 레벨로 consumer는 읽는다.


### Consumer의 subscribe, poll, commit 로직
- kafka consumer 는 poll() 메소드를 이용하여 주기적으로 브로커의 토픽 파티션에서 메시지를 가져옴. 메시지를 성공적으로 가져 왔으면 commit을 통해서 __consumer_offset에 다음에 읽을 offset 위치를 기재함.

01-8 consumer의 subscribe, poll, commit 로직.png

# 01-4 Producer의 객체 직렬화(Serializer) 전송의 이해

- producer와 consumer 간에는 serialized message (byte 형태로된)만 전송이 되며, broker는 무조건 객체 직렬화된 byte 만을 취급한다.
<br><br>

1. Producer에서 key와 value는 무조건 serializer 직렬화해서 byte[] 형태로 바꾼다.
2. 객체 직렬화된 byte array로 broker에 전송된다.

- partition에 저장되는 형태는 byte array로 저장

3. Consumer에선 byte array를 받아, deserializer 역직렬화를 수행하여 key value를 객체 형태로 복원시킨다.

<br><br>

### Producer 와 Consumer에서 직렬화/역직렬화 적용

01-9 Producer와 consumer에서 직렬화 역직렬화 적용.png

- 내부적으로 stringSerializer, IntegerSerializer 등을 통해서 byte array 로 변환됨. 
  - 해당 serializer 들은 카프카 클라이언트에서 기본적으로 이미 내장되어 있음.
  - 근데, 객체 object 의 직렬화의 경우, custom 직렬화 코드를 짜줘야 함.


- kafka console producer, consumer는 String 형으로 key, value 라고 가정하고 진행. 
  - 그러나, java client 에서 할 때는 형에 따라서 빨간 부분처럼 명식적으로 적어줘야 함.
  - Integer key value 면 IntegerSerializer


**kafka 에서 기본 제공하는 serializer**
- StringSerializer, ShortSerializer, IntegerSerializer, LongSerializer, DoubleSerializer, BytesSerializer

<br><br>

**자바 객체(Object)의 Serialization**

객체 object를 객체의 유형, 데이터의 포맷, 적용 시스템에 상관없이 이동, 저장, 복원을 자유롭게 하기 위해서 

바이트 배열(바이트 스트림) 형태로 저장하는 것.

<br>

객체는 serialization 과 deserialization 을 통해서 system to system 또는 서로 다른 저장영역에 이동, 저장, 복원을 자유롭게 수행


# 01-5 key값을 가지는 메시지 전송

**Partitioner**
각각의 파티션은 독립적인 로그파일로 되어 있는데, 해당 메시지들이 어떤 파티션 으로 전송되어야 할지 미리 결정해주는 곳. 

producer는 처음에 broker에 접속하면 broker에서 메타데이터(ex. 토픽 a는 파티션2개다.)를 받고, partitioner가 어디로 보낼지 전략적으로 정하게 된다.

### key 값을 가지지 않는 메시지 전송
- 메시지는 Producer를 통해 전송 시, Partitioner를 통해 토픽의 어떤 파티션으로 전송되어야 할 지 미리 결정이 됨.
- key값을 가지지 않는 경우, 라운드 로빈, 스티키 파티션 등의 파티션 전략 등이 선택되어 파티션 별로 메시지를 전송될 수 있음.
- Topic이 **여러 개의 파티션**을 가질 때, 메시지의 **전송 순서가 보장되지 않은** 채로 consumer 에서 읽혀질 수 있음.
  - 분산 시스템이니깐 어떻게 보면 당연한 맥락
  - 이때 만약,순서를 보장하고 싶으면 partition을 하나 쓸 수 밖에 없다.

### key 값을 가지는 메시지 전송
- 메시지 key는 업무 로직이나 메시지 produce, consume 시 분산 성능 영향을 고려하여 생성
- **특정 key 값**을 가지는 메시지는 **특정 파티션으로 고정되어 전송됨.**
  - hasing 알고리즘을 걸쳐서, 같은 key값이 또 들어오면, 같은 파티션으로 전송이 되게 된다. => 전송순서를 보장할 수 있게 된다.
- 특정 key 값을 가지는 메시지는 단일 파티션 내에서 전송 순서가 보장되어 consumer 에서 읽혀짐.

<br><br>

**주의.**
- 메시지 key 값이 메시지를 고유하게 식별하는 것은 아니다.
- key 01 이 여러 메시지를 보낼 수 있음. 해당 메시지 별로, 식별하는 게 아님.


# 01-7 key가 없는 메시지의 파티션 분배전략 - 라운드 로빈과 스티키 파티셔닝


### 1. 라운드 로빈 
- kafka 2.4 버전 이전 기본 파티션 분배 전략
- 최대한 메시지를 파티션에 균일하게 분배하려는 전략으로 **메시지 배치를 순차적으로 다른 파티션으로 전송**함.
  - 즉, 배치 끼리. 배치 별로 특정 파티션으로 가게 됨.

- 메시지가 배치 데이터를 빨리 채우지 못하면서 전송이 늦어지거나 배치를 다 채우지 못하고 전송하면서 전송 성능이 떨어지는 문제 발생
  - 배치에  batch.size 사이즈 만큼 차면 보내거나, linger.ms 다른 요소에 의해 이를 만족하면, send 한다. 이때, 어떤 배치는 다 채워지지 않았는데 전송되게 됨.
  - => 이러한 라운드 로빈 성능을 개선하고자 스티키 파티셔닝전략이 나옴.


<br><br>

### 2. 스티키 파티셔닝 
- kafka 2.4 버전부터 기본 파티션 분배 전략
- 라운드 로빈의 성능을 개선하고자 특정 파티션으로 전송되는 하나의 배치에 메시지를 빠르게 먼저 채워서 보내는 방식
- 배치를 채우지 못하고 전송하거나 배치를 채우는데 시간이 너무 오래 걸리는 문제를 개선

- ex. 1,2,3 들어왔을 때, batch 0에 1, batch 1에 2 가 아니라, 일단 batch 0에 1,2,3 을 채움. 그리고 batch 사이즈 다 챘을 때 얘를 보냄.


# 01-8 Consumer Grop 과 Consumer 의 이해

모든 consumer 들은 **단 하나의 consumer group 에 소속** (여러 그룹에 속 할 수 없음) 되어야 하며,

Consumer Group 은 1개 이상의 consumer 를 가질 수 있음.

파티션의 레코드들은 단 하나의 consumer 에만 할당. 즉, **하나의 파티션은 단 하나의 consumer** 로 가는 것.

- 보통 partition 의 갯수만큼 동일하게 consumer 갯수를 맞춰줌.
  - partion 이 많을 수록 전송속도를 병렬분산시켜, 성능을 향상 시킬 수 있는데, consumer 를 늘리지 않는다면 병목 현상과 동일할 것이다. 
  - => partition을 늘리는 만큼 받아드리는 consumer 를 늘려야 함. 

- consumer group 삭제 
  - consumer group 의 consumer 가 다 삭제되더라도 며칠 간 group을 보관하고 있다가 7일 뒤(파라미터 조절 가능) 삭제

- consumer 만들 때, consumer-id 이 할당되는데, 우리가 정하는 것이 아니라, broker에서 정함.

### 1. Conusmer Group 내 1개의 Consumer 만 있을 경우

01-10 consumer group 내에 1개의 consumer.png

- 모든 partition이 하나의 consumer 에 할당
- producer에서 배치 별로 partition들에 들어올 텐데, 이를 consumer 가 읽어들일 때, producer 에서 분배해서 보내는 것대로 순차적으로 안 들어 올 수 있음. 순서 보장 안 됨.


### 2. Consumer Group 내에 2개의 Consumer 가 있지만 토픽 파티션 개수보다 작을 경우

01-11 group 내 2개의 consumer.png

- 파티션들을 consumer 그룹 내에서 consumer 들이 나눠 가짐. 


**Rebalancing**
- **consumer group 내에 consumer 변화가 있을 시(consumer 가 생기고, 없어질 때)** 마다 **파티션과 consumer 의 조합을 변경**하는 rebalancing 이 발생
  - 또 다른 consumer 가 생기면 생긴 consumer 가 파티션을 나눠 가지는 등


### 3. Conusmer Group 내에 파티션 개수와 동일한 Consumer 가 있을 경우

01-12 group 내 파티션 개수와 동일한 consumer.png

- 파티션 하나에 consumer 하나씩 할당


### 4. group 내 파티션 개수보다 많은 consumer 가 있을 경우
- 하나의 파티션은 consumer4도 가고 consumer 5도 가는 것이 아님. 단 하나의 consumer 에 할당 되는 것.
- rebalancing 시, consumer4에 가는 게 5로 갈 수도 있지만 어쨌든 consumer 가 더 많을 경우, 노는 consumer가 생긴다.


### 5. 하나의 토픽을 여러 개의 Consumer Group 이 subscribe 할 경우
- consumer group 끼리 분업하지 않음. 서로 다른 consumer group 의 consumer들은 각자 알아서 **분리되어 독립적**으로 동작.

**Consumer group.id**
- 동일한 Consumer Group내의 consumer 들은 작업량을 **최대한 균등하게 분배**
- 모든 consumer 들은 고유한 그룹 아이디 group.id 를 가지는 consumer group 에 소속되어야 함. 개별 consumer group 내에서 여러 개의 consumer들은 토픽 파티션 별로 분배됨.


# 01-9 카프카 환경 파라미터의 구분 및 kafka-configs 명령어로 파라미터 검색 및 수정 적용하기

### kafka config 구분 및 이해

1. Broker 레벨 config 와 Topic 레벨 config 
- kafka 서버에서 설정되는 config
- topic의 config 값은 broker 레벨에서 지정한 config 를 기본으로 설정하며 별도의 topic 레벨 config 를 설정할 경우 이를 따름.
  - 보통은 모든 topic에 대해서 적용하는 것에 대해서 broker config 에서 설정함. 
  - 그 외에 특정 topic 에 한해서 설정하고 싶을 때 topic config 에 설정
-  보통 server.properties 에 있는 config 는 변경 시, broker 재기동이 필요한 static config이며, Dynamic config는 kafka-configs를 이용하여 동적으로 config 변경 가능.
2. Producer와 Consumer 레벨 config
- kafka 클라이언트에서 설정되는 config
- client 레벨에서 설정되므로 server.properties 에 존재하지 않고, kafka-configs로 수정할 수 없으며, client 수행시 마다 설정할 수 있음.
- properites 객체나 hashmap나 map 객체에 properties 를 담아, 수행할 때 마다 client 레벨에서 설정

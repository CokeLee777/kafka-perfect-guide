# Java 기반 Consumer 구현 실습 및 Consumer 내부 메커니즘 이해-01

## 1. Consumer 주요 메커니즘 개요

### Consumer 란?
- 브로커의 Topic 메시지를 읽는 역할을 수행
- 모든 Consumer들은 고유한 그룹아이디 group.id 를 가지는 Consumer Group 에 소속되어야 함.
- 개별 Consumer Group 내에서 여러 개의 Consumer 들은 토픽 파티션 별로 분배됨.
- 보통, 가장 좋은 성능을 위해, partition 갯수에 맞춰 consumer 갯수를 구성한다.
- consumer 또한 배치 단위로 메시지를 읽는다.

<br>

**필수 properties 객체 config**

- bootstrap.servers
key.deserializer.class, value.deserializer
- group.id 
  - CLI 할 때는 안 해도 자동으로 설정해줬으나, java client 의 경우, 필수. 안 해도 구동은 되나, 종료 시켜버림.

<br>

## 2. Consumer 의 subscribe, poll, commit 로직

01-8 consumer의 subscribe, poll, commit 로직.png

### 1. **subscribe()**
- consumer는 subscribe()를 호출하여 
  
  읽어 들이려는 토픽 즉, 어떤 토픽을 읽을지를 등록한다.

  그러면 metadata (partition 정보 등)을 받는다.

<br>

### 2. **poll()**
- 실제로 consumer가 메시지를 들고오는 메소드
- cunsumer 는 poll() 메소드를 이용하여 **주기적으로** 브로커의 토픽 파티션에서 **메시지를 가져온다.**
- ```kafkaConsumer.poll(Duration.ofMillis(1000)```
  - 브로커나 Consumer 내부 Queue에 데이터가 있으면, 바로 데이터를 반환
  - 가져올 데이터가 없으면, 최.대. 1000ms 1초동안 기다린다.
  
    기다려도 안 오면, Fetch를 브로커에 계속 수행하고 결과 반환한다.

- 첫번째 poll 에서 많은 일을 수행한다.
  - metadata를 broker와 교환
  - Heart Beat Thread 를 만든다.

![image](https://github.com/CokeLee777/kafka-perfect-guide/assets/66711073/5570db0e-b055-47d1-887a-522c3da86469)


**과정**

- 데이터가 있어, 1초를 안 기다리는 경우,

  1. Fetcher 가 Linked Queue 를 본다. 
  2. Linked Queue에 없으면, ConsumerNetworkClient가 비동기 I.O 로 토픽을 들고 오게 한다.
  3. 없는 메시지가 broker 토픽에 있다면, ConsumerNetworkClient 가 가져와, Linked Queue에 넣는다.

    ConsumerNetworkClient는 비동기로 계속 브로커의 메시지를 가져와서 Linked Queue에 저장하는 것 까지 수행한다.
  4. Linked Queue에 데이터 생겼기에 Fetcher가 데이터를 가져오고 반환하며 poll() 수행 완료

- 최신 데이터가 없어, 1초를 기다리는 경우 기다려도 안 오는 경우,

  1. Linked Queue에 데이터가 없음. 1000ms 까지 기다림.
  2. 1000ms 까지 broker에 메시지 요청 후, poll 수행() 완료


<br>

### 3. **commit()**
- 메시지를 성공적으로 가져 왔으면 commit 을 통해서

  __consumer_offset 에 다음에 읽을 offset 위치를 기재함.

### ❓ __consumer_offsets

- 내부 토픽
- 다음에 읽을 offset 정보를 알 수 있다.
- consumer가 topic 에 처음 접속한 경우, offset 정보가 없음. 그때, auto.offset.reset 파라미터를 통해 메시지를 가져온다.
  - auto.offset.reset = earliest : 처음 offett 부터 읽음. 
  - auto.offset.reset = latest : 마지막 offset 부터 읽음. 디폴트.
    
    메시지 로그 파일에 있는 offset + 1 부터 읽는다.

### auto.offset.reset
- 앞에서 consumer가 topic 에 처음 접속한 경우, 이라고 말을 하긴 했지만, 뭐가 됐든

  알아야 할 것은,

  **__consumer_offsets 에 offset 정보가 없을 경우에만,**
  
  해당 파라미터가 적용된다는 게 중요.!!

- 동일 Consumer Group 으로 Consumer를 새롭게 접속할 시, __consumer_offsets 에 있는 offset 정보를 기반으로 메시지를 가져오기 때문에 earliest 로 설정하여도 0번 오프셋부터 읽어 들이지 않음.


- Consumer Group 의 Consumer 가 모두 종료 되면, Consumer group 도 없어지지만,
  
  Consumer Group 이 읽어들인 offset 정보는
  
  7일동안 __consumer_offsets 에 저장되어 있음.! (offsets.retention.minutes)

- 해당 Topic 이 삭제되고 재생성될 경우에는 해당 topic에 대한 ConsumerGroup 의 offset 정보는 0으로 __consumer_offsets으로 기록됨.

-  재기동 해든 뭐든,  __consumer_offsets 에 값이 있다면,earliest 이든 뭐든 __consumer_offsets 대로 읽는다.






## 3. KafkaConsumer의 주요 수행 개요 및 구성 요소
- KafkaConsumer는 Fetcher, ConsumerClientNetwork 등의 주요 내부 객체와 별도의 Heart Beat Thread 를 생성

<br>

1. Heart Beat Thread
- 해당 thread 가 consumer 가 살아있음을 계속 브로커에게 보낸다.
- Heart Beat Thread는 consumer의 정상적인 활동을 
  
  Group Coordinator에 보고하는 역할을 수행
  
  (Group Coordinator는 주어진 시간동안 HeartBeat을 받지 못하면 consumer 들의 rebalance를 수행 명령)
- 별도의 thread

2. Fetcher, ConsumerClientNetwork 
- Fetcher, ConsumerClientNetwork 객체는 Broker의 토픽 파티션에서 메시지를 Fetch 및 Poll 수행
- 이 두 개가 협력을 해서 broker 로부터 메시지를 읽는 것.

3. SubscriptionState
- topic을 subscript 하는 state 를 변경하는 것.

4. ConsumerCoordinator
- consumer group 상태를 관리하고 인터페이스에서 정보를 가져온다.

<br>

## 4. Consumer Fetcher 프로세스 개요

### 1. Consumer Fetcher 관련 주요 설정 파라미터

**👍 해당 파라미터를 조절해, 배치 사이즈를 조절.**

<br>

1. ```fetch.min.byte```
- Fetcher가 record들을 읽어들이는 최소 bytes.
  - Fetcher 가 ConsumerNetworkClient 에게 메시지 올 것을 요청하는 최소 bytes
- 브로커는 지정된 fetch.min.bytes 이상의 새로운 메시지가 쌓일 때까지 전송을 하지 않음.
  - 설정한 bytes 만큼 메시지가 토픽에 쌓이면, ConsumerNetworkClient 가 바로 consumer로 들고옴.
- 기본은 1bytes
- 언제 이만큼이 쌓일지 무작정 기다릴 수 없으니, 아래 파라미터로 대기 시간 조절

2. ```fetch.max.wait.ms```
- 브로커에 fetch.min.bytes 이상의 메시지가 쌓일 때까지 최대 대기 시간.
- bytes 가 설정된 만큼 쌓이면, 대기 시간 파라미터와 상관없이 바로 들고 가고,

  안 쌓여도 해당 대기 시간 이상되면, 들고 감.
- 기본은 500ms

<br>

3. ```fetch.max.bytes```
- fetcher가 한 번에 가져올 수 있는 최대 데이터 bytes.
- 기본 50MB

4. ```max.partition.fetch.bytes```
- Fetcher 가 파티션별로 한번에 최대로 가져올 수 있는 bytes
- 기본 1MB
  - 파티션 100개면 fetcher가 한 번에 가져올 수 있는 데이터가 100MB 

    이때, 만약, fetch.max.bytes = 50MB 라면, 50 MB로 제약.

<br>

**🚨 위 4개는 ConsumerClientNetwork 가 broker로 부터 들고 오는 과정과 관련된 파라미터**

  **아래 5번째 파라미터는 Fetcher가 Linked Queue에서 가져오는 과정과 관련된 파라미터**

<br>

5. ```max.poll.records```
- Fetcher가 Linked Queue에서 한번에 가져올 수 있는 레코드 수
- 해당 파라미터 갯수만큼 가져가고, 남으면, ConsumerClientNetwork 에 다시 요청할 필요없이,

  다음에 들고 감.
- 기본 500

<br>

**❓poll(Duration.ofMillis(1000)) VS fetch.max.wait.ms**

- poll(Duration.ofMillis(1000)) 는 레코드가 없는 상황에서, 1000ms까지 기다리는 것.
- fetch.max.wait.ms는 레코드가 있는 상황에서, bytes 까지 차도록 기다리는 것.

### 2. Consumer Fetcher 관련 주요 설정 파라미터 이해

- poll(Duration.ofMillis(1000)) 을 가정.

1. 가져올 데이터가 1건도 없으면 poll() 인자 시간만큼 대기 후 return

   <br>

2. 가져와야 할 과거 데이터가 많을 경우,

  즉, 오랜 과거 offset 데이터를 가져온다면,

  max.partition.fetch.bytes 로 배치 크기 설정.

  최대 max.partition.fetch.bytes 만큼 파티션에서 읽은 뒤 반환.

<br>

3. 그렇지 않을 경우, fetch.min.bytes 로 배치 크기 설정
  
  즉, 가정 최신의 offset 데이터를 가져오고 있다면,
  
  fetch.min.bytes 만큼 가져오고 return 하고
  
  fetch.min.bytes 만큼 쌓이지 않는다면,
  
  fetch.max.wait.ms 만큼 기다린 후 return

  max.partition.fetch.bytes 에 도달하지 못하여도 가장 최신의 offset에 도달하면 반환.

4. 토픽에 파티션이 많아도 가져오는 데이터량은 fetch.max.bytes로 제한

   <br>

5. Fetcher 가 Linked Queue에서 가져오는 레코드의 개수는 max.poll.records 로 제한

<br>

**✏️ 요약**

기본적으로 fetch.min.bytes 파라미터 기준으로 가져오고,

가져와야 할 과거 데이터가 많을 경우, max.partition.fetch.bytes 로 배치 크기 설정해 가져온다.


